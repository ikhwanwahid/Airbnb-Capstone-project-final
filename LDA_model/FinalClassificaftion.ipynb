{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8TjqY0RrDsin"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cw4YLqDOD5yZ"
   },
   "outputs": [],
   "source": [
    "comments=pd.read_csv('./final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12219,
     "status": "ok",
     "timestamp": 1579097466419,
     "user": {
      "displayName": "ikhwan wahid",
      "photoUrl": "",
      "userId": "01550124214470849109"
     },
     "user_tz": -480
    },
    "id": "FsTIoVz8EDvA",
    "outputId": "050b8c7b-97eb-47cf-8925-260ace2d4998"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346959, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12208,
     "status": "ok",
     "timestamp": 1579097466420,
     "user": {
      "displayName": "ikhwan wahid",
      "photoUrl": "",
      "userId": "01550124214470849109"
     },
     "user_tz": -480
    },
    "id": "JsZAgdE-RoGC",
    "outputId": "33fdd86a-c350-463e-b6e8-a0f322f0cd90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comments    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12196,
     "status": "ok",
     "timestamp": 1579097466421,
     "user": {
      "displayName": "ikhwan wahid",
      "photoUrl": "",
      "userId": "01550124214470849109"
     },
     "user_tz": -480
    },
    "id": "KwV4Wg5pEG8K",
    "outputId": "bae6898d-7541-46ff-9bb5-19723470132d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stephanie was a wonderful host! Her apartment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Such a wonderful place and very close to the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I just got back from a trip to NYC during whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stephanie's offered all the most important thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stephanie was really nice, ftiendly and helpfu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments\n",
       "0  Stephanie was a wonderful host! Her apartment ...\n",
       "1  Such a wonderful place and very close to the m...\n",
       "2  I just got back from a trip to NYC during whic...\n",
       "3  Stephanie's offered all the most important thi...\n",
       "4  Stephanie was really nice, ftiendly and helpfu..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EgZGdEFfRtzc"
   },
   "outputs": [],
   "source": [
    "comments.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12169,
     "status": "ok",
     "timestamp": 1579097466423,
     "user": {
      "displayName": "ikhwan wahid",
      "photoUrl": "",
      "userId": "01550124214470849109"
     },
     "user_tz": -480
    },
    "id": "OszTOhNfR09j",
    "outputId": "54e01240-38ba-4ecb-b6a1-d0ed565c0ec9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comments    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F7wQ4VtrEJNd"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M0ijcOxpFD7q"
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o6n0OUfgG_qL"
   },
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMQ86soEHCXa"
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3717,
     "status": "error",
     "timestamp": 1579104688249,
     "user": {
      "displayName": "ikhwan wahid",
      "photoUrl": "",
      "userId": "01550124214470849109"
     },
     "user_tz": -480
    },
    "id": "aIQIt1S1HDut",
    "outputId": "ba5a77f7-24ac-4cfe-ca95-11489b2454a4"
   },
   "outputs": [],
   "source": [
    "# for plotting\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1090,
     "status": "ok",
     "timestamp": 1579104688731,
     "user": {
      "displayName": "ikhwan wahid",
      "photoUrl": "",
      "userId": "01550124214470849109"
     },
     "user_tz": -480
    },
    "id": "Id0ziFwXHHpJ",
    "outputId": "86d00c5e-75aa-4666-8a52-33c371f33ac8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPjf6vPnHNRe"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWKVUZ8QHYVf"
   },
   "outputs": [],
   "source": [
    "# Convert email body to list\n",
    "data = comments.comments.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9GvMXkp0Hijx"
   },
   "outputs": [],
   "source": [
    "# tokenize - break down each sentence into a list of words\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RIkIqjOHjaj"
   },
   "outputs": [],
   "source": [
    "data_words=list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56077,
     "status": "ok",
     "timestamp": 1579097510415,
     "user": {
      "displayName": "ikhwan wahid",
      "photoUrl": "",
      "userId": "01550124214470849109"
     },
     "user_tz": -480
    },
    "id": "cvLuG8taH83O",
    "outputId": "b443b349-d652-4404-affe-5fac9a3e3208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stephanie', 'offered', 'all', 'the', 'most', 'important', 'things', 'warm', 'welcome', 'into', 'comfortable', 'home', 'comfortable', 'bed', 'in', 'quiet', 'room', 'fresh', 'clean', 'towels', 'blankets', 'and', 'easy', 'access', 'to', 'manhattan', 'finding', 'myself', 'travelling', 'to', 'nyc', 'in', 'the', 'future', 'feel', 'already', 'have', 'open', 'invitation', 'to', 'make', 'home', 'away', 'from', 'home', 'through', 'stephanie', 'generousity']\n"
     ]
    }
   ],
   "source": [
    "print(data_words[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OD7FEQ-YIY5w"
   },
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 184555,
     "status": "ok",
     "timestamp": 1579097638912,
     "user": {
      "displayName": "ikhwan wahid",
      "photoUrl": "",
      "userId": "01550124214470849109"
     },
     "user_tz": -480
    },
    "id": "I3cxLZj2Ihe7",
    "outputId": "968903dc-75ed-4a5c-94f3-62cc8de90fca"
   },
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = Phrases(bigram[data_words], threshold=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wd-NghitJPxO"
   },
   "outputs": [],
   "source": [
    "bigram_mod = Phraser(bigram)\n",
    "trigram_mod = Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 222576,
     "status": "ok",
     "timestamp": 1579097676953,
     "user": {
      "displayName": "ikhwan wahid",
      "photoUrl": "",
      "userId": "01550124214470849109"
     },
     "user_tz": -480
    },
    "id": "Ip2KmEs4KCYd",
    "outputId": "39e242af-5075-44ba-a589-f6546669d64a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best', 'host', 'ever', 'had', 'stefanie', 'and', 'her', 'family', 'are', 'very', 'kind', 'helpful', 'and', 'accommodating', 'you', 'will', 'feel', 'at', 'home', 'here', 'immediately', 'the', 'place', 'is', 'very', 'nice', 'clean', 'and', 'you', 'can', 'beat', 'the', 'access', 'to', 'both', 'the', 'and', 'as', 'well', 'as', 'the', 'and', 'subway', 'lines', 'both', 'each', 'blocks', 'away', 'will', 'definitely', 'come', 'back']\n"
     ]
    }
   ],
   "source": [
    "print(trigram_mod[bigram_mod[data_words[35]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mtf5G5poKORL"
   },
   "outputs": [],
   "source": [
    "#remove stop_words, make bigrams and lemmatize\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpB1xfluOXif"
   },
   "outputs": [],
   "source": [
    "data_words_nostops = remove_stopwords(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxUE-FPXPelY"
   },
   "outputs": [],
   "source": [
    "data_words_bigrams = make_bigrams(data_words_nostops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NuyG5xmRQpSH",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = en_core_web_sm.load(disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "27PGc8xmQyvt"
   },
   "outputs": [],
   "source": [
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_nrrjOwA9UF"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SMuFo4jlodpl"
   },
   "outputs": [],
   "source": [
    "f=open(\"./model/data_lemmatized_final.pkl\",'wb')\n",
    "pickle.dump(data_lemmatized,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVDB7hIM8qA7"
   },
   "outputs": [],
   "source": [
    "#data_lemmatized = []\n",
    "#with (open(\"data_lemmatized.pkl\", \"rb\")) as openfile:\n",
    "    #while True:\n",
    "        #try:\n",
    "        #    data_lemmatized.append(pickle.load(openfile))\n",
    "        #except EOFError:\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hd3KaarzQ1U2"
   },
   "outputs": [],
   "source": [
    "#data_lemmatized=data_lemmatized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1023,
     "status": "ok",
     "timestamp": 1579104938749,
     "user": {
      "displayName": "ikhwan wahid",
      "photoUrl": "",
      "userId": "01550124214470849109"
     },
     "user_tz": -480
    },
    "id": "Osx_IOgF_NcU",
    "outputId": "bf3bd02b-dedb-401a-b85b-dff12b8c0cb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346959"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H9xYcI2DUUKn"
   },
   "outputs": [],
   "source": [
    "#create a dictionary and corpus for (LDA topic modeling)\n",
    "\n",
    "#creating the dictionary\n",
    "\n",
    "idtoword=corpora.Dictionary(data_lemmatized)\n",
    "#create corpus\n",
    "\n",
    "texts=data_lemmatized\n",
    "\n",
    "corpus=[idtoword.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346959"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NMURl6ybVDVK"
   },
   "source": [
    "# Gensim LDA Model -Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 195355,
     "status": "error",
     "timestamp": 1579124928690,
     "user": {
      "displayName": "ikhwan wahid",
      "photoUrl": "",
      "userId": "01550124214470849109"
     },
     "user_tz": -480
    },
    "id": "Iku129aeVHIA",
    "outputId": "6b53b1f2-8381-4710-94a2-1db4c989381d"
   },
   "outputs": [],
   "source": [
    "#build our LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=idtoword,\n",
    "                                           num_topics=5,\n",
    "                                           workers=3,\n",
    "                                           random_state=100,\n",
    "                                           eval_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"./model/lda_model_final.pkl\",'wb')\n",
    "pickle.dump(lda_model,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(lda_model, open(\"./model/lda.pickle\", \"wb\"))\n",
    "pickle.dump(idtoword, open(\"./model/idatoword_final.pickle\", \"wb\"))\n",
    "pickle.dump(corpus, open(\"./model/corpus_final.pickle\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mbOKW8bdfDvg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.041*\"close\" + 0.036*\"walk\" + 0.032*\"subway\" + 0.031*\"apartment\" + 0.028*\"restaurant\" + 0.028*\"great\" + 0.023*\"place\" + 0.019*\"minute\" + 0.018*\"station\" + 0.018*\"location\"'), (1, '0.022*\"host\" + 0.020*\"day\" + 0.013*\"night\" + 0.013*\"arrival\" + 0.012*\"check\" + 0.012*\"apartment\" + 0.012*\"get\" + 0.010*\"reservation\" + 0.010*\"cancel\" + 0.010*\"place\"'), (2, '0.044*\"stay\" + 0.029*\"place\" + 0.022*\"make\" + 0.019*\"feel\" + 0.018*\"home\" + 0.015*\"time\" + 0.015*\"thank\" + 0.014*\"back\" + 0.014*\"come\" + 0.014*\"host\"'), (3, '0.074*\"room\" + 0.037*\"good\" + 0.030*\"clean\" + 0.029*\"bed\" + 0.024*\"apartment\" + 0.024*\"bathroom\" + 0.023*\"nice\" + 0.018*\"well\" + 0.018*\"comfortable\" + 0.016*\"kitchen\"'), (4, '0.097*\"great\" + 0.063*\"place\" + 0.055*\"stay\" + 0.054*\"location\" + 0.041*\"host\" + 0.037*\"clean\" + 0.029*\"recommend\" + 0.027*\"apartment\" + 0.021*\"nice\" + 0.018*\"good\"')]\n"
     ]
    }
   ],
   "source": [
    "print(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_ZjS6EpvIcT"
   },
   "outputs": [],
   "source": [
    "lda_model.save('ldafinal.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Msqfp6Tk0eq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el193481165622147285215302427\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el193481165622147285215302427_data = {\"mdsDat\": {\"x\": [0.04636973379466236, -0.13256987987083033, 0.3046390056381266, -0.18875745578721212, -0.02968140377474625], \"y\": [-0.1533666797778984, -0.11329243695072452, -0.006637149354438957, -0.013994304816017378, 0.2872905708990793], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [23.25046730041504, 21.08717918395996, 20.870744705200195, 18.759042739868164, 16.032564163208008]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [195276.0, 85723.0, 60519.0, 118501.0, 50616.0, 43602.0, 191769.0, 119340.0, 38092.0, 186827.0, 114285.0, 42179.0, 94371.0, 27882.0, 74287.0, 46753.0, 30750.0, 24335.0, 45111.0, 46342.0, 34920.0, 40413.0, 46224.0, 29807.0, 69831.0, 21645.0, 31693.0, 18495.0, 38672.0, 25449.0, 30749.052734375, 8390.2490234375, 6715.69091796875, 6219.01904296875, 5458.244140625, 3732.213134765625, 3590.330810546875, 2716.162109375, 2257.2607421875, 2046.9678955078125, 1972.6275634765625, 1922.3787841796875, 1806.974365234375, 1788.6842041015625, 1675.3033447265625, 1554.686279296875, 1448.8118896484375, 1443.9849853515625, 1321.9666748046875, 1325.13623046875, 1206.8636474609375, 1227.87255859375, 1200.7421875, 1028.0084228515625, 1012.9786987304688, 993.315185546875, 978.1168823242188, 972.9805297851562, 948.0558471679688, 981.02392578125, 24039.36328125, 31377.57421875, 13168.171875, 37675.35546875, 3694.318359375, 23094.10546875, 12307.7431640625, 18493.5390625, 3003.819091796875, 25502.865234375, 13286.0654296875, 6563.654296875, 20758.083984375, 16257.30859375, 19434.28125, 12889.509765625, 10732.634765625, 14754.693359375, 73591.9609375, 11575.1640625, 9985.9130859375, 25505.302734375, 21516.68359375, 12011.77734375, 10585.857421875, 49262.578125, 12148.0390625, 9280.876953125, 18129.34765625, 12090.884765625, 17217.609375, 22758.103515625, 14630.2119140625, 15526.169921875, 14427.720703125, 12609.7109375, 1506.5084228515625, 1240.6416015625, 997.953857421875, 699.80810546875, 696.7698364257812, 675.3966674804688, 634.4508056640625, 640.0968017578125, 641.8118286132812, 553.3499755859375, 372.341796875, 260.03656005859375, 251.585205078125, 240.4592742919922, 237.29013061523438, 226.36181640625, 228.5963592529297, 222.5439910888672, 216.82205200195312, 246.52911376953125, 219.34141540527344, 210.10671997070312, 284.1268005371094, 168.24322509765625, 167.53895568847656, 163.611572265625, 160.60157775878906, 151.7976837158203, 220.6785888671875, 177.74520874023438, 3708.554443359375, 18052.982421875, 15666.00390625, 1245.0316162109375, 4343.53564453125, 147424.65625, 17099.0, 1817.336181640625, 18636.63671875, 2086.9716796875, 81953.9296875, 672.4698486328125, 10899.3232421875, 6040.1962890625, 5385.509765625, 7184.7119140625, 43931.359375, 10045.013671875, 14928.22265625, 12106.2783203125, 96133.078125, 26728.302734375, 62643.24609375, 20458.814453125, 57029.83203125, 8188.75341796875, 26067.84375, 83146.765625, 10406.5615234375, 24706.91015625, 9892.3037109375, 4764.39599609375, 32482.064453125, 20295.001953125, 12344.0068359375, 41524.47265625, 27285.6953125, 19499.84765625, 13717.9091796875, 17164.44921875, 15496.953125, 13169.0947265625, 12117.625, 18922.888671875, 15298.591796875, 15161.708984375, 11140.8359375, 9634.0087890625, 8769.7646484375, 7193.611328125, 6384.4794921875, 6059.701171875, 5386.30419921875, 5130.91455078125, 4716.82666015625, 4515.39111328125, 4505.15771484375, 4476.875, 4532.34912109375, 4182.49609375, 4031.185546875, 3864.956787109375, 3685.900390625, 3652.26611328125, 3512.78369140625, 3386.528076171875, 3318.160888671875, 3301.6455078125, 3264.167236328125, 2976.921630859375, 2794.625732421875, 2688.56640625, 2648.989990234375, 12985.8994140625, 6558.54248046875, 30881.353515625, 10758.2392578125, 5393.09375, 7583.2099609375, 9612.2607421875, 6482.619140625, 20329.6640625, 9043.34375, 7685.20263671875, 17561.765625, 7364.73046875, 33938.49609375, 18382.111328125, 7465.318359375, 9151.7421875, 8770.7998046875, 8083.76708984375, 17853.310546875, 12237.669921875, 8187.64208984375, 8401.7099609375, 8813.6611328125, 14882.046875, 14529.5458984375, 8351.759765625, 9077.2392578125, 8970.708984375, 8708.7568359375, 43601.44921875, 38091.07421875, 24334.716796875, 21644.736328125, 18666.373046875, 16165.828125, 15679.3662109375, 14624.8212890625, 11758.806640625, 11035.90625, 9572.052734375, 8016.66162109375, 6877.58740234375, 6806.99169921875, 5478.82470703125, 5298.28955078125, 5087.1806640625, 4349.4921875, 4106.49755859375, 3735.243896484375, 3712.5595703125, 3482.11767578125, 3050.513671875, 3071.10595703125, 2457.295166015625, 2308.116943359375, 2133.13037109375, 1600.011474609375, 1540.360107421875, 1529.360107421875, 48848.85546875, 55331.6171875, 4957.09814453125, 8915.181640625, 25122.494140625, 8394.7734375, 20284.869140625, 6248.6328125, 23353.787109375, 10792.9609375, 13367.1591796875, 7637.49951171875, 16437.791015625, 16321.701171875, 41595.6484375, 19426.369140625, 11330.1962890625, 37346.2421875, 14659.3203125, 31491.12890625, 24178.650390625, 11918.0478515625, 17736.8046875, 14849.876953125, 12921.28125, 13621.8369140625, 13046.828125, 85722.1640625, 18494.380859375, 10628.0859375, 9481.46484375, 9127.873046875, 5118.0087890625, 4940.56787109375, 3118.33447265625, 2933.937744140625, 2837.54052734375, 2786.468994140625, 2788.107666015625, 2557.6201171875, 2425.626953125, 2251.847412109375, 2126.54345703125, 1781.899169921875, 1743.887451171875, 1684.517822265625, 1612.054443359375, 27862.578125, 1298.779296875, 1293.827392578125, 1285.4764404296875, 1279.52490234375, 1251.0479736328125, 1218.5889892578125, 1174.522216796875, 1162.8310546875, 1066.7415771484375, 3237.59326171875, 6064.263671875, 33699.4375, 17951.24609375, 17619.390625, 3657.569580078125, 11161.9794921875, 9218.0908203125, 7847.203125, 42601.59765625, 12696.4892578125, 4323.46484375, 3688.75732421875, 20787.462890625, 26954.765625, 35069.34765625, 15894.6787109375, 20545.44140625, 27927.93359375, 8082.18310546875, 4770.50830078125, 7128.66748046875, 13115.470703125, 5483.5166015625, 9242.6884765625, 6753.72509765625, 8339.451171875, 8867.521484375, 8706.8388671875, 5748.22900390625, 7260.5556640625], \"Term\": [\"great\", \"room\", \"close\", \"location\", \"walk\", \"subway\", \"place\", \"host\", \"restaurant\", \"stay\", \"clean\", \"bed\", \"good\", \"bathroom\", \"nice\", \"make\", \"home\", \"station\", \"check\", \"easy\", \"feel\", \"day\", \"definitely\", \"minute\", \"recommend\", \"train\", \"locate\", \"kitchen\", \"thank\", \"back\", \"home\", \"ever\", \"parking\", \"tip\", \"hope\", \"truly\", \"sparkle\", \"suggestion\", \"brand\", \"gem\", \"advice\", \"chance\", \"exceed\", \"favorite\", \"williamsburg\", \"wine\", \"forward\", \"treat\", \"art\", \"deli\", \"invite\", \"necessity\", \"ease\", \"unique\", \"roomy\", \"lucky\", \"beautifully\", \"emily\", \"authentic\", \"water_pressure\", \"back\", \"feel\", \"sure\", \"make\", \"soon\", \"come\", \"welcome\", \"love\", \"relax\", \"thank\", \"give\", \"absolutely\", \"go\", \"experience\", \"amazing\", \"airbnb\", \"beautiful\", \"even\", \"stay\", \"wonderful\", \"help\", \"time\", \"definitely\", \"much\", \"visit\", \"place\", \"enjoy\", \"trip\", \"really\", \"city\", \"need\", \"host\", \"perfect\", \"recommend\", \"apartment\", \"comfortable\", \"breeze\", \"checkin\", \"roof\", \"communicating\", \"amazingly\", \"communicator\", \"def\", \"timely\", \"seamless\", \"hustle\", \"readily\", \"venue\", \"ue\", \"manhatten\", \"homey\", \"responsiveness\", \"unwind\", \"accomodating\", \"added_bonu\", \"cake\", \"china_town\", \"tasteful\", \"pauline\", \"solo\", \"newyork\", \"stacy\", \"jasmine\", \"le\", \"maggie\", \"victor\", \"communicative\", \"communication\", \"responsive\", \"adorable\", \"flexible\", \"great\", \"quick\", \"prompt\", \"highly\", \"smooth\", \"location\", \"inquiry\", \"respond\", \"response\", \"communicate\", \"exactly\", \"recommend\", \"value\", \"helpful\", \"excellent\", \"place\", \"check\", \"host\", \"super\", \"clean\", \"awesome\", \"easy\", \"stay\", \"question\", \"definitely\", \"accommodate\", \"describe\", \"nice\", \"perfect\", \"friendly\", \"apartment\", \"good\", \"comfortable\", \"amazing\", \"really\", \"need\", \"thank\", \"space\", \"arrival\", \"reservation\", \"cancel\", \"issue\", \"noise\", \"key\", \"however\", \"early\", \"bad\", \"flight\", \"luggage\", \"hear\", \"stair\", \"cold\", \"pay\", \"process\", \"dirty\", \"loud\", \"hard\", \"lock\", \"due\", \"noisy\", \"bag\", \"smell\", \"elevator\", \"heat\", \"heater\", \"wall\", \"later\", \"fix\", \"floor\", \"hot\", \"day\", \"door\", \"unit\", \"late\", \"leave\", \"hour\", \"night\", \"bit\", \"say\", \"get\", \"arrive\", \"host\", \"check\", \"problem\", \"sleep\", \"work\", \"thing\", \"apartment\", \"time\", \"use\", \"find\", \"even\", \"place\", \"stay\", \"little\", \"make\", \"also\", \"go\", \"subway\", \"restaurant\", \"station\", \"train\", \"block\", \"distance\", \"shop\", \"bar\", \"nearby\", \"line\", \"park\", \"bus\", \"square\", \"transportation\", \"conveniently\", \"downtown\", \"public\", \"ride\", \"grocery\", \"attraction\", \"supermarket\", \"cafe\", \"market\", \"midtown\", \"shopping\", \"centrally\", \"metro\", \"public_transport\", \"chinatown\", \"ferry\", \"walk\", \"close\", \"min\", \"store\", \"minute\", \"stop\", \"away\", \"corner\", \"locate\", \"food\", \"many\", \"central\", \"lot\", \"neighborhood\", \"apartment\", \"easy\", \"right\", \"great\", \"area\", \"place\", \"location\", \"quiet\", \"good\", \"nice\", \"also\", \"stay\", \"clean\", \"room\", \"kitchen\", \"large\", \"share\", \"private\", \"privacy\", \"living\", \"bath\", \"fully\", \"quality\", \"table\", \"property\", \"closet\", \"common\", \"necessary\", \"sofa\", \"separate\", \"polite\", \"soft\", \"appliance\", \"bathroom\", \"utensil\", \"landlord\", \"chair\", \"bottle\", \"suitable\", \"satisfied\", \"dust\", \"cooking\", \"desk\", \"linen\", \"tv\", \"bed\", \"bedroom\", \"small\", \"cook\", \"big\", \"live\", \"towel\", \"good\", \"people\", \"equip\", \"size\", \"well\", \"nice\", \"clean\", \"space\", \"comfortable\", \"apartment\", \"sleep\", \"full\", \"price\", \"really\", \"quite\", \"area\", \"use\", \"locate\", \"also\", \"need\", \"enough\", \"location\"], \"Total\": [195276.0, 85723.0, 60519.0, 118501.0, 50616.0, 43602.0, 191769.0, 119340.0, 38092.0, 186827.0, 114285.0, 42179.0, 94371.0, 27882.0, 74287.0, 46753.0, 30750.0, 24335.0, 45111.0, 46342.0, 34920.0, 40413.0, 46224.0, 29807.0, 69831.0, 21645.0, 31693.0, 18495.0, 38672.0, 25449.0, 30750.037109375, 8391.2373046875, 6716.6923828125, 6220.0048828125, 5459.234375, 3733.19677734375, 3591.326171875, 2717.150634765625, 2258.26513671875, 2047.9500732421875, 1973.617919921875, 1923.367431640625, 1807.95751953125, 1789.669921875, 1676.2957763671875, 1555.6778564453125, 1449.798095703125, 1444.9696044921875, 1322.9493408203125, 1326.15625, 1207.85009765625, 1228.8792724609375, 1201.7427978515625, 1028.9915771484375, 1013.9786376953125, 994.30615234375, 979.1012573242188, 973.9913940429688, 949.0436401367188, 982.05517578125, 25449.4140625, 34920.0546875, 15141.6259765625, 46753.33984375, 3974.41552734375, 28836.419921875, 15311.7509765625, 24011.83984375, 3330.911865234375, 38672.75, 18463.08984375, 8602.4482421875, 35083.828125, 26192.96484375, 33152.9765625, 20103.7578125, 16256.0283203125, 24936.638671875, 186827.296875, 18785.74609375, 15565.25390625, 53750.94140625, 46224.3828125, 21589.435546875, 18431.365234375, 191769.09375, 23009.998046875, 15347.5849609375, 56742.140625, 25729.423828125, 52749.99609375, 119340.390625, 42702.8359375, 69831.8828125, 143329.09375, 58452.33203125, 1507.5826416015625, 1241.744140625, 999.0646362304688, 700.8901977539062, 697.8529052734375, 676.4592895507812, 635.5092163085938, 641.171875, 642.8899536132812, 554.4780883789062, 373.4779357910156, 261.13330078125, 252.66046142578125, 241.5352325439453, 238.3985595703125, 227.43145751953125, 229.68763732910156, 223.61964416503906, 217.90158081054688, 247.7864990234375, 220.48207092285156, 211.21080017089844, 285.9121398925781, 169.34716796875, 168.64724731445312, 164.7274932861328, 161.70217895507812, 152.85711669921875, 222.2541961669922, 179.03135681152344, 3766.76123046875, 21224.88671875, 18341.744140625, 1336.6856689453125, 4943.17431640625, 195276.921875, 21194.638671875, 2010.2861328125, 23960.01171875, 2380.908935546875, 118501.984375, 719.3505249023438, 14036.9765625, 7598.95068359375, 6887.13916015625, 9629.056640625, 69831.8828125, 14149.138671875, 21994.33984375, 17891.865234375, 191769.09375, 45111.23046875, 119340.390625, 33928.53125, 114285.40625, 12013.783203125, 46342.5390625, 186827.296875, 16322.4052734375, 46224.3828125, 15544.125, 6667.0771484375, 74287.2265625, 42702.8359375, 24262.1328125, 143329.09375, 94371.046875, 58452.33203125, 33152.9765625, 56742.140625, 52749.99609375, 38672.75, 38301.79296875, 18923.89453125, 15299.5908203125, 15162.70703125, 11141.8466796875, 9635.01953125, 8770.7763671875, 7194.62255859375, 6385.49267578125, 6060.7109375, 5387.31494140625, 5131.92724609375, 4717.83447265625, 4516.39990234375, 4506.17236328125, 4477.8896484375, 4533.3935546875, 4183.5, 4032.19189453125, 3865.974853515625, 3686.909912109375, 3653.27734375, 3513.79296875, 3387.538818359375, 3319.174072265625, 3302.662353515625, 3265.177734375, 2977.9384765625, 2795.634765625, 2689.579833984375, 2649.9951171875, 13040.2626953125, 6565.62939453125, 40413.27734375, 12538.181640625, 5978.0234375, 9345.7724609375, 12640.9404296875, 7680.9091796875, 33054.75, 12723.3486328125, 10765.04296875, 38885.5390625, 10392.423828125, 119340.390625, 45111.23046875, 10650.1318359375, 17234.67578125, 16702.05859375, 16327.029296875, 143329.09375, 53750.94140625, 18193.890625, 20532.013671875, 24936.638671875, 191769.09375, 186827.296875, 21916.740234375, 46753.33984375, 42842.265625, 35083.828125, 43602.421875, 38092.046875, 24335.689453125, 21645.7109375, 18667.349609375, 16166.7998046875, 15680.3369140625, 14625.7939453125, 11759.78125, 11036.880859375, 9573.02734375, 8017.6376953125, 6878.56298828125, 6807.9638671875, 5479.80224609375, 5299.26513671875, 5088.1513671875, 4350.46826171875, 4107.47021484375, 3736.21484375, 3713.53125, 3483.08935546875, 3051.485107421875, 3072.088134765625, 2458.27001953125, 2309.09326171875, 2134.099609375, 1600.985595703125, 1541.339599609375, 1530.33349609375, 50616.640625, 60519.59765625, 5080.25537109375, 9380.6767578125, 29807.103515625, 9201.3271484375, 25193.0546875, 6818.98095703125, 31693.955078125, 13699.1923828125, 18203.09765625, 9664.9443359375, 29374.54296875, 30880.791015625, 143329.09375, 46342.5390625, 20498.240234375, 195276.921875, 33537.08984375, 191769.09375, 118501.984375, 26137.1640625, 94371.046875, 74287.2265625, 42842.265625, 186827.296875, 114285.40625, 85723.15625, 18495.373046875, 10629.0791015625, 9482.4580078125, 9128.87109375, 5119.00634765625, 4941.55810546875, 3119.32763671875, 2934.935546875, 2838.535400390625, 2787.4599609375, 2789.109130859375, 2558.6142578125, 2426.6171875, 2252.852294921875, 2127.531005859375, 1782.888671875, 1744.8951416015625, 1685.510986328125, 1613.049072265625, 27882.53125, 1299.7679443359375, 1294.822021484375, 1286.46630859375, 1280.5355224609375, 1252.0386962890625, 1219.595703125, 1175.5205078125, 1163.8212890625, 1067.7493896484375, 3266.162353515625, 6399.087890625, 42179.890625, 21439.458984375, 22197.16015625, 4081.25390625, 15011.55078125, 13021.384765625, 10841.8076171875, 94371.046875, 21946.8984375, 5601.7978515625, 4639.17724609375, 47084.6953125, 74287.2265625, 114285.40625, 38301.79296875, 58452.33203125, 143329.09375, 17234.67578125, 7556.69921875, 16725.587890625, 56742.140625, 10342.9931640625, 33537.08984375, 18193.890625, 31693.955078125, 42842.265625, 52749.99609375, 12465.443359375, 118501.984375], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.458799958229065, 1.4586999416351318, 1.4586999416351318, 1.4586999416351318, 1.4586999416351318, 1.4586000442504883, 1.4586000442504883, 1.4585000276565552, 1.458400011062622, 1.458400011062622, 1.458299994468689, 1.458299994468689, 1.458299994468689, 1.458299994468689, 1.458299994468689, 1.4581999778747559, 1.4581999778747559, 1.4581999778747559, 1.4580999612808228, 1.4580999612808228, 1.4579999446868896, 1.4579999446868896, 1.4579999446868896, 1.457900047302246, 1.457900047302246, 1.457800030708313, 1.457800030708313, 1.457800030708313, 1.457800030708313, 1.457800030708313, 1.4018000364303589, 1.3518999814987183, 1.319200038909912, 1.2430000305175781, 1.3858000040054321, 1.236799955368042, 1.2404999732971191, 1.197700023651123, 1.3554999828338623, 1.0425000190734863, 1.1297999620437622, 1.1883000135421753, 0.9340000152587891, 0.9818999767303467, 0.9247999787330627, 1.0144000053405762, 1.0436999797821045, 0.9340999722480774, 0.5271999835968018, 0.9746000170707703, 1.0149999856948853, 0.7134000062942505, 0.6941999793052673, 0.8725000023841858, 0.9042999744415283, 0.09969999641180038, 0.8201000094413757, 0.9557999968528748, 0.31790000200271606, 0.7037000060081482, 0.3391999900341034, -0.19820000231266022, 0.38769999146461487, -0.04470000043511391, -0.8371000289916992, -0.07490000128746033, 1.555799961090088, 1.5556000471115112, 1.555400013923645, 1.5549999475479126, 1.5549999475479126, 1.554900050163269, 1.554800033569336, 1.554800033569336, 1.554800033569336, 1.5544999837875366, 1.5535000562667847, 1.552299976348877, 1.5521999597549438, 1.5520000457763672, 1.551800012588501, 1.551800012588501, 1.5516999959945679, 1.5516999959945679, 1.5514999628067017, 1.5513999462127686, 1.551300048828125, 1.551300048828125, 1.5501999855041504, 1.5499999523162842, 1.5499000549316406, 1.5497000217437744, 1.5497000217437744, 1.5494999885559082, 1.549399971961975, 1.549299955368042, 1.5408999919891357, 1.3946000337600708, 1.398800015449524, 1.4854999780654907, 1.4271999597549438, 1.2754000425338745, 1.3417999744415283, 1.4556000232696533, 1.3051999807357788, 1.4247000217437744, 1.1877000331878662, 1.4890999794006348, 1.3035000562667847, 1.3269000053405762, 1.3106000423431396, 1.263700008392334, 1.093000054359436, 1.2138999700546265, 1.1690000295639038, 1.1658999919891357, 0.8658999800682068, 1.0331000089645386, 0.9120000004768372, 1.0506999492645264, 0.8614000082015991, 1.173200011253357, 0.9811000227928162, 0.7469000220298767, 1.1064000129699707, 0.9301000237464905, 1.104599952697754, 1.2204999923706055, 0.7293000221252441, 0.8126000165939331, 0.8808000087738037, 0.3176000118255615, 0.3156000077724457, 0.4587000012397766, 0.6740999817848206, 0.36079999804496765, 0.33160001039505005, 0.47920000553131104, 0.4056999981403351, 1.5667999982833862, 1.5667999982833862, 1.5667999982833862, 1.5666999816894531, 1.5666999816894531, 1.5666999816894531, 1.5666999816894531, 1.5666999816894531, 1.5666999816894531, 1.56659996509552, 1.56659996509552, 1.56659996509552, 1.56659996509552, 1.56659996509552, 1.56659996509552, 1.56659996509552, 1.56659996509552, 1.56659996509552, 1.56659996509552, 1.566499948501587, 1.566499948501587, 1.566499948501587, 1.566499948501587, 1.566499948501587, 1.566499948501587, 1.566499948501587, 1.566499948501587, 1.566499948501587, 1.5664000511169434, 1.5664000511169434, 1.562600016593933, 1.5657000541687012, 1.2977999448776245, 1.413699984550476, 1.4638999700546265, 1.357800006866455, 1.2928999662399292, 1.3971999883651733, 1.0807000398635864, 1.2253999710083008, 1.2297999858856201, 0.7718999981880188, 1.2223999500274658, 0.3093999922275543, 0.6690999865531921, 1.2115000486373901, 0.9337999820709229, 0.9226999878883362, 0.8639000058174133, -0.5160999894142151, 0.08699999749660492, 0.7684000134468079, 0.67330002784729, 0.5267999768257141, -0.989300012588501, -0.9872000217437744, 0.6019999980926514, -0.0723000019788742, 0.0032999999821186066, 0.17339999973773956, 1.6734999418258667, 1.6734999418258667, 1.6734999418258667, 1.6734000444412231, 1.6734000444412231, 1.6734000444412231, 1.6734000444412231, 1.6734000444412231, 1.6734000444412231, 1.6734000444412231, 1.6734000444412231, 1.6734000444412231, 1.6734000444412231, 1.6734000444412231, 1.67330002784729, 1.67330002784729, 1.67330002784729, 1.67330002784729, 1.67330002784729, 1.673200011253357, 1.673200011253357, 1.673200011253357, 1.673200011253357, 1.673200011253357, 1.6730999946594238, 1.6730999946594238, 1.6729999780654907, 1.6728999614715576, 1.6728999614715576, 1.6728999614715576, 1.6378999948501587, 1.583899974822998, 1.6490000486373901, 1.6225999593734741, 1.502500057220459, 1.5817999839782715, 1.4567999839782715, 1.5860999822616577, 1.3681000471115112, 1.4350999593734741, 1.3646999597549438, 1.438099980354309, 1.092900037765503, 1.0358999967575073, 0.43630000948905945, 0.804099977016449, 1.0806000232696533, 0.019300000742077827, 0.8458999991416931, -0.1331000030040741, 0.08399999886751175, 0.8881999850273132, 0.0019000000320374966, 0.06350000202655792, 0.4747999906539917, -0.9449999928474426, -0.4966999888420105, 1.8305000066757202, 1.8305000066757202, 1.8305000066757202, 1.830399990081787, 1.830399990081787, 1.830399990081787, 1.830299973487854, 1.830199956893921, 1.830199956893921, 1.830199956893921, 1.830199956893921, 1.830199956893921, 1.830199956893921, 1.8301000595092773, 1.8301000595092773, 1.8301000595092773, 1.8300000429153442, 1.8300000429153442, 1.8300000429153442, 1.8299000263214111, 1.829800009727478, 1.829800009727478, 1.829800009727478, 1.829800009727478, 1.829800009727478, 1.829800009727478, 1.829699993133545, 1.829699993133545, 1.829699993133545, 1.8295999765396118, 1.8217999935150146, 1.7768000364303589, 1.6060999631881714, 1.652999997138977, 1.5995999574661255, 1.720900058746338, 1.5341999530792236, 1.4851000308990479, 1.5073000192642212, 1.0351999998092651, 1.2832000255584717, 1.5714999437332153, 1.6013000011444092, 1.0130000114440918, 0.8167999982833862, 0.6492000222206116, 0.9509999752044678, 0.7850000262260437, 0.19499999284744263, 1.0733000040054321, 1.3705999851226807, 0.9776999950408936, 0.36579999327659607, 1.1959999799728394, 0.541700005531311, 0.8396000266075134, 0.49540001153945923, 0.25540000200271606, 0.029100000858306885, 1.05649995803833, -0.961899995803833], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.0015997886657715, -5.300300121307373, -5.5229997634887695, -5.599800109863281, -5.730299949645996, -6.110400199890137, -6.149199962615967, -6.428199768066406, -6.61329984664917, -6.711100101470947, -6.748000144958496, -6.773900032043457, -6.8358001708984375, -6.845900058746338, -6.911399841308594, -6.986100196838379, -7.056700229644775, -7.059999942779541, -7.1483001708984375, -7.145899772644043, -7.2393999099731445, -7.222099781036377, -7.244500160217285, -7.399799823760986, -7.4145002365112305, -7.434100151062012, -7.44950008392334, -7.454800128936768, -7.480800151824951, -7.446599960327148, -4.247700214385986, -3.981300115585327, -4.849599838256836, -3.7983999252319336, -6.12060022354126, -4.287799835205078, -4.917200088500977, -4.510000228881836, -6.327499866485596, -4.188600063323975, -4.840700149536133, -5.545899868011475, -4.394499778747559, -4.638899803161621, -4.460400104522705, -4.870999813079834, -5.054100036621094, -4.735899925231934, -3.1289000511169434, -4.978600025177002, -5.126200199127197, -4.188499927520752, -4.35860013961792, -4.941500186920166, -5.06790018081665, -3.5302999019622803, -4.930200099945068, -5.19950008392334, -4.529900074005127, -4.934999942779541, -4.581500053405762, -4.302499771118164, -4.74429988861084, -4.684899806976318, -4.758299827575684, -4.892899990081787, -6.920000076293945, -7.114099979400635, -7.3317999839782715, -7.686699867248535, -7.691100120544434, -7.7221999168396, -7.784800052642822, -7.775899887084961, -7.773200035095215, -7.921500205993652, -8.317700386047363, -8.6766996383667, -8.709699630737305, -8.755000114440918, -8.768199920654297, -8.815400123596191, -8.8056001663208, -8.83240032196045, -8.858400344848633, -8.729999542236328, -8.84689998626709, -8.889900207519531, -8.58810043334961, -9.112099647521973, -9.116299629211426, -9.140000343322754, -9.158599853515625, -9.21500015258789, -8.840800285339355, -9.05720043182373, -6.019100189208984, -4.436399936676025, -4.5782999992370605, -7.110599994659424, -5.861100196838379, -2.336400032043457, -4.490699768066406, -6.732399940490723, -4.404600143432617, -6.593999862670898, -2.9235999584198, -7.726600170135498, -4.941100120544434, -5.531300067901611, -5.645999908447266, -5.357800006866455, -3.547100067138672, -5.02269983291626, -4.626500129699707, -4.835999965667725, -2.7639999389648438, -4.044000148773193, -3.1923000812530518, -4.311299800872803, -3.2862000465393066, -5.2270002365112305, -4.0690999031066895, -2.90910005569458, -4.987299919128418, -4.122700214385986, -5.038000106811523, -5.768599987030029, -3.849100112915039, -4.319399833679199, -4.8165998458862305, -3.6034998893737793, -4.023399829864502, -4.359300136566162, -4.711100101470947, -4.4868998527526855, -4.589099884033203, -4.7519001960754395, -4.835100173950195, -4.3790998458862305, -4.591700077056885, -4.6006999015808105, -4.90880012512207, -5.054100036621094, -5.148099899291992, -5.346199989318848, -5.46560001373291, -5.5177998542785645, -5.6356000900268555, -5.684199810028076, -5.7683000564575195, -5.8119001388549805, -5.814199924468994, -5.820499897003174, -5.808199882507324, -5.888500213623047, -5.9253997802734375, -5.96750020980835, -6.014900207519531, -6.024099826812744, -6.063000202178955, -6.099599838256836, -6.119999885559082, -6.125, -6.13640022277832, -6.228499889373779, -6.2916998863220215, -6.330399990081787, -6.345300197601318, -4.7555999755859375, -5.438700199127197, -3.8893001079559326, -4.94379997253418, -5.634300231933594, -5.293499946594238, -5.056399822235107, -5.450300216674805, -4.307400226593018, -5.117400169372559, -5.280099868774414, -4.453700065612793, -5.322700023651123, -3.7948999404907227, -4.408100128173828, -5.309199810028076, -5.105500221252441, -5.1479997634887695, -5.229599952697754, -4.43720006942749, -4.814899921417236, -5.216800212860107, -5.190999984741211, -5.143099784851074, -4.61929988861084, -4.6433000564575195, -5.197000026702881, -5.113699913024902, -5.125500202178955, -5.155099868774414, -3.437700033187866, -3.5727999210357666, -4.020899772644043, -4.138000011444092, -4.285999774932861, -4.429900169372559, -4.460400104522705, -4.53000020980835, -4.748199939727783, -4.811600208282471, -4.95389986038208, -5.131199836730957, -5.2845001220703125, -5.2947998046875, -5.511899948120117, -5.545400142669678, -5.585999965667725, -5.742700099945068, -5.80019998550415, -5.894999980926514, -5.901000022888184, -5.965099811553955, -6.097499847412109, -6.090700149536133, -6.313700199127197, -6.376299858093262, -6.4552001953125, -6.742800235748291, -6.780799865722656, -6.787899971008301, -3.3239998817443848, -3.199399948120117, -5.6118998527526855, -5.025000095367432, -3.989000082015991, -5.08519983291626, -4.202899932861328, -5.38040018081665, -4.061999797821045, -4.833899974822998, -4.619999885559082, -5.179699897766113, -4.4131999015808105, -4.420300006866455, -3.484800100326538, -4.246099948883057, -4.785299777984619, -3.5924999713897705, -4.527699947357178, -3.7630999088287354, -4.027299880981445, -4.7347002029418945, -4.337100028991699, -4.514800071716309, -4.653900146484375, -4.601099967956543, -4.644199848175049, -2.604599952697754, -4.138199806213379, -4.692200183868408, -4.806399822235107, -4.844399929046631, -5.422900199890137, -5.458199977874756, -5.918399810791016, -5.979400157928467, -6.012800216674805, -6.030900001525879, -6.030300140380859, -6.116600036621094, -6.169600009918213, -6.24399995803833, -6.301199913024902, -6.478000164031982, -6.499599933624268, -6.534200191497803, -6.578199863433838, -3.7283999919891357, -6.794300079345703, -6.798099994659424, -6.804599761962891, -6.809199810028076, -6.831699848175049, -6.857999801635742, -6.894899845123291, -6.904900074005127, -6.991099834442139, -5.880899906158447, -5.253300189971924, -3.5381999015808105, -4.168099880218506, -4.186699867248535, -5.758900165557861, -4.643199920654297, -4.834499835968018, -4.99560022354126, -3.303800106048584, -4.514400005340576, -5.591700077056885, -5.750400066375732, -4.021399974822998, -3.7616000175476074, -3.4983999729156494, -4.289700031280518, -4.033100128173828, -3.726099967956543, -4.966100215911865, -5.493299961090088, -5.091599941253662, -4.481900215148926, -5.354000091552734, -4.831900119781494, -5.145599842071533, -4.934700012207031, -4.873300075531006, -4.891600131988525, -5.30679988861084, -5.073299884796143]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 3, 2, 2, 2, 3, 1, 1, 3, 1, 2, 3, 4, 5, 1, 2, 2, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 3, 1, 3, 1, 4, 1, 1, 4, 1, 2, 1, 3, 3, 3, 4, 5, 3, 5, 1, 2, 4, 1, 2, 3, 5, 3, 5, 1, 3, 4, 5, 3, 5, 4, 5, 1, 2, 4, 4, 2, 3, 2, 3, 4, 4, 5, 1, 2, 3, 2, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 2, 4, 5, 3, 1, 3, 1, 2, 4, 5, 5, 2, 3, 2, 2, 3, 2, 3, 2, 4, 1, 4, 5, 5, 3, 4, 1, 3, 4, 2, 1, 2, 1, 1, 2, 3, 4, 5, 5, 3, 4, 3, 4, 4, 3, 5, 3, 1, 1, 2, 3, 4, 3, 1, 1, 2, 4, 5, 1, 3, 4, 5, 4, 5, 1, 3, 5, 1, 1, 2, 5, 1, 2, 4, 5, 1, 2, 3, 5, 1, 1, 3, 5, 4, 1, 2, 3, 4, 5, 3, 2, 3, 3, 3, 5, 1, 3, 4, 1, 1, 2, 4, 5, 1, 3, 4, 5, 5, 1, 1, 2, 3, 4, 1, 3, 5, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 4, 4, 3, 3, 3, 3, 1, 2, 3, 5, 1, 2, 4, 5, 1, 2, 4, 1, 2, 1, 1, 2, 3, 3, 5, 3, 4, 3, 2, 2, 3, 1, 3, 2, 3, 5, 5, 5, 1, 3, 3, 2, 1, 3, 4, 3, 5, 1, 2, 3, 4, 5, 1, 3, 5, 5, 4, 5, 2, 3, 4, 5, 3, 1, 3, 4, 5, 3, 1, 2, 1, 3, 2, 1, 3, 2, 1, 3, 4, 5, 4, 4, 4, 3, 4, 3, 4, 1, 2, 3, 4, 5, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 4, 5, 2, 2, 4, 5, 1, 2, 3, 4, 5, 3, 3, 4, 1, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 2, 3, 5, 5, 5, 3, 4, 5, 3, 2, 3, 5, 4, 4, 5, 1, 2, 4, 5, 2, 3, 4, 1, 2, 4, 5, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 4, 3, 2, 3, 2, 3, 2, 3, 4, 2, 4, 4, 1, 3, 4, 2, 5, 1, 5, 1, 3, 2, 5, 5, 4, 4, 2, 3, 4, 5, 3, 5, 3, 4, 5, 3, 2, 3, 5, 5, 2, 1, 3, 1, 2, 5, 1, 4, 2, 3, 4, 1, 2, 3, 4, 5, 3, 4, 3, 4, 4, 1, 5, 1, 2, 4, 5, 4, 1, 3, 5, 2, 1, 2, 1, 3, 4, 5, 1, 2, 3, 4, 2, 1, 3, 5, 4, 4, 1, 1, 2, 3, 4, 1, 3, 5, 2, 1, 2, 3, 2, 1, 3, 5, 5, 2, 5, 2, 2, 1, 2, 4, 3, 4, 3, 1, 1, 2, 5, 1, 2, 4, 5, 1, 1, 1, 2, 1, 2, 3, 4, 5], \"Freq\": [0.7630385756492615, 0.23690930008888245, 0.28390148282051086, 0.6363819241523743, 0.07964424043893814, 0.9972290396690369, 0.9958624243736267, 0.9314082264900208, 0.06807883083820343, 0.9996868968009949, 0.6411736607551575, 0.35883837938308716, 0.23301754891872406, 0.04901701584458351, 0.20939601957798004, 0.30159470438957214, 0.20699185132980347, 0.586191713809967, 0.4137788414955139, 0.9987778067588806, 0.1006634458899498, 0.2897109091281891, 0.12455949932336807, 0.2902132272720337, 0.19485227763652802, 0.9993496537208557, 0.16870874166488647, 0.11834658682346344, 0.00023854186292737722, 0.4370981454849243, 0.27560532093048096, 0.9999527335166931, 0.29126986861228943, 0.7086893320083618, 0.9992824196815491, 0.9996748566627502, 0.9989003539085388, 0.19477590918540955, 0.8051822185516357, 0.3183010518550873, 0.6816337704658508, 0.9445797204971313, 0.05536473169922829, 0.999882698059082, 0.9998409152030945, 0.9999457001686096, 0.9995743632316589, 0.0006814302178099751, 0.9992995262145996, 0.6602473855018616, 0.3372902572154999, 0.0023991100024431944, 0.9988752603530884, 0.11906147748231888, 0.08198219537734985, 0.7989352345466614, 0.16264402866363525, 0.8372879028320312, 0.13662812113761902, 0.012523689307272434, 0.10725074261426926, 0.7435607314109802, 0.7107405662536621, 0.28915342688560486, 0.9999276995658875, 0.9995818138122559, 0.9994397759437561, 0.9996135234832764, 0.9999204874038696, 0.9996872544288635, 0.9968258738517761, 0.9999533891677856, 0.19782835245132446, 0.01189867127686739, 0.7901752591133118, 0.9995265603065491, 0.9988601803779602, 0.9992890357971191, 0.5924910306930542, 0.40748167037963867, 0.9994007349014282, 0.9932780265808105, 0.99913090467453, 0.46992892026901245, 0.1759464144706726, 0.0035368066746741533, 0.35053253173828125, 0.07391145080327988, 0.49901384115219116, 0.006055016536265612, 0.11416155844926834, 0.30685457587242126, 0.08570777624845505, 0.9142823219299316, 0.9997599124908447, 0.9997398257255554, 0.8008622527122498, 0.19912318885326385, 0.21573133766651154, 0.33360517024993896, 0.09917482733726501, 0.35148298740386963, 0.9997456669807434, 0.7820373177528381, 0.21794244647026062, 0.9987298846244812, 0.8505581617355347, 0.14940008521080017, 0.98466557264328, 0.015132363885641098, 0.9978427290916443, 0.9998536109924316, 0.0249923188239336, 0.07865229994058609, 0.8962931632995605, 0.9992943406105042, 0.08359020203351974, 0.9164125919342041, 0.21656249463558197, 0.7641300559043884, 0.01927584409713745, 0.9976251721382141, 0.4654902517795563, 0.5345014333724976, 0.9991281032562256, 0.04844701662659645, 0.7145559787750244, 0.0860946998000145, 0.053996674716472626, 0.0968940332531929, 0.9992981553077698, 0.999641478061676, 0.9999505281448364, 0.8580191731452942, 0.1418866068124771, 0.9997612833976746, 0.9996503591537476, 0.9995571970939636, 0.9997662305831909, 0.9993818998336792, 0.0006473534158430994, 0.562506914138794, 0.017651168629527092, 0.4191828966140747, 0.9997994303703308, 0.9989821314811707, 0.5279444456100464, 0.3088657259941101, 0.15445460379123688, 0.008735333569347858, 0.25077328085899353, 0.12257887423038483, 0.1655777394771576, 0.461114764213562, 0.22814103960990906, 0.7717165350914001, 0.5916996598243713, 0.3534558117389679, 0.054859038442373276, 0.9998525381088257, 0.16751381754875183, 0.7461790442466736, 0.08619743585586548, 0.9994704127311707, 0.676620364189148, 0.14637936651706696, 0.17695192992687225, 0.6206628680229187, 0.23510129749774933, 0.13862501084804535, 0.005612194072455168, 0.9996256828308105, 0.898566722869873, 0.09971347451210022, 0.0017182104056701064, 0.9991286396980286, 0.2907167375087738, 0.06088053435087204, 0.4092146158218384, 0.2012466937303543, 0.037940751761198044, 0.999624490737915, 0.8787875175476074, 0.12117719650268555, 0.9997559189796448, 0.9958388209342957, 0.004141021054238081, 0.13402250409126282, 0.07810679078102112, 0.7878566384315491, 0.9994494915008545, 0.30038580298423767, 0.5087763667106628, 0.04030973091721535, 0.1505226343870163, 0.20974765717983246, 0.06722512096166611, 0.09170670807361603, 0.6313602924346924, 0.9996812343597412, 0.9995360970497131, 0.23101133108139038, 0.07025747746229172, 0.45163318514823914, 0.2470841407775879, 0.7195978760719299, 0.24995815753936768, 0.03038494661450386, 0.5916686058044434, 0.24823403358459473, 0.1601022481918335, 0.07121887803077698, 0.28913527727127075, 0.0002755082387011498, 0.18794959783554077, 0.4514308273792267, 0.05379540100693703, 0.7549535036087036, 0.19124636054039001, 0.9996420741081238, 0.9997478127479553, 0.9998231530189514, 0.9996393322944641, 0.9996848702430725, 0.6415571570396423, 0.11352208256721497, 0.18155823647975922, 0.06334622204303741, 0.27861714363098145, 0.6787200570106506, 0.00754739623516798, 0.03509993851184845, 0.221535786986351, 0.7778376936912537, 0.0006260431255213916, 0.9999662637710571, 0.9941335320472717, 0.9997739195823669, 0.19069822132587433, 0.5249102711677551, 0.28437983989715576, 0.9989902973175049, 0.0009138499153777957, 0.8440406918525696, 0.15597112476825714, 0.9999134540557861, 0.9973342418670654, 0.9341760277748108, 0.06394657492637634, 0.9992961883544922, 0.9999240040779114, 0.9956575632095337, 0.9999114871025085, 0.9999257922172546, 0.9993651509284973, 0.9998984932899475, 0.1885344386100769, 0.8113828897476196, 0.9997844099998474, 0.9943926930427551, 0.23953914642333984, 0.7603864669799805, 0.9999201893806458, 0.00857275165617466, 0.9913775324821472, 0.11885891854763031, 0.06314807385206223, 0.3810785710811615, 0.22553536295890808, 0.2113909274339676, 0.27546992897987366, 0.01658809743821621, 0.7079124450683594, 0.9998870491981506, 0.7368597388267517, 0.26311010122299194, 0.6915833353996277, 0.04311320185661316, 0.20403878390789032, 0.0612732358276844, 0.9997531771659851, 0.19707541167736053, 0.045209214091300964, 0.5596001744270325, 0.1981307417154312, 0.9997044205665588, 0.7702033519744873, 0.22980329394340515, 0.9986863732337952, 0.9998193383216858, 0.9943569302558899, 0.8058247566223145, 0.1941465586423874, 0.9936438798904419, 0.13893239200115204, 0.06987821310758591, 0.7343255877494812, 0.056803517043590546, 0.999841034412384, 0.9994847178459167, 0.9996458292007446, 0.024014540016651154, 0.9757383465766907, 0.1571437418460846, 0.8428192138671875, 0.5563832521438599, 0.11950289458036423, 0.15854977071285248, 0.015007340349256992, 0.15053659677505493, 0.9999335408210754, 0.9996216893196106, 0.9992845058441162, 0.32640761137008667, 0.2937820255756378, 0.07292891293764114, 0.14183887839317322, 0.16506162285804749, 0.20909439027309418, 0.1715305745601654, 0.5285486578941345, 0.0908331647515297, 0.9961621165275574, 0.4372487962245941, 0.19989977777004242, 0.3628483712673187, 0.14932800829410553, 0.0724857971072197, 0.6150401830673218, 0.10999932140111923, 0.05315423756837845, 0.9998942017555237, 0.9997743368148804, 0.9998927116394043, 0.9998969435691833, 0.0034975779708474874, 0.9933121204376221, 0.9998013377189636, 0.06934920698404312, 0.0712629184126854, 0.18891051411628723, 0.09190364927053452, 0.5784872174263, 0.3426001965999603, 0.4752611815929413, 0.18211905658245087, 0.2568870782852173, 0.5012955665588379, 0.07760374248027802, 0.1642131209373474, 0.9994869828224182, 0.3803752660751343, 0.1933564394712448, 0.4262331426143646, 0.9998034238815308, 0.9999045729637146, 0.7009302973747253, 0.07145451754331589, 0.22750891745090485, 0.9996926188468933, 0.9038514494895935, 0.09550879150629044, 0.9996023178100586, 0.9997737407684326, 0.9993844032287598, 0.9998114109039307, 0.24163106083869934, 0.6375898718833923, 0.066227987408638, 0.054526276886463165, 0.8067606091499329, 0.042888205498456955, 0.15032103657722473, 0.06680142879486084, 0.24700461328029633, 0.4559790790081024, 0.23024685680866241, 0.21183423697948456, 0.25795242190361023, 0.5302140116691589, 0.996042788028717, 0.3194980025291443, 0.3024912178516388, 0.0038595653604716063, 0.14299777150154114, 0.2311333268880844, 0.22233396768569946, 0.6290966272354126, 0.09267973154783249, 0.05589137598872185, 0.9018551707267761, 0.0978710949420929, 0.9999613761901855, 0.7764492630958557, 0.2234811782836914, 0.7948465943336487, 0.20502831041812897, 0.8541172742843628, 0.13417480885982513, 0.011667374521493912, 0.9937059879302979, 0.9999725222587585, 0.9996625185012817, 0.3223203420639038, 0.12488877028226852, 0.5527303814888, 0.9989343881607056, 0.9999865293502808, 0.9990348815917969, 0.9995115399360657, 0.28601837158203125, 0.7138847708702087, 0.9986156821250916, 0.9995015263557434, 0.9998462200164795, 0.9999147653579712, 0.9994833469390869, 0.10950217396020889, 0.0010777773568406701, 0.09441329538822174, 0.7951840758323669, 0.5310224890708923, 0.46893832087516785, 0.10028310120105743, 0.10591445118188858, 0.7937501668930054, 0.9996462464332581, 0.8765559792518616, 0.12306224554777145, 0.9997504353523254, 0.9996968507766724, 0.9920449256896973, 0.9294448494911194, 0.07019899785518646, 0.2686297297477722, 0.3163820505142212, 0.41499361395835876, 0.9996307492256165, 0.9999181628227234, 0.9955836534500122, 0.999690055847168, 0.9999716877937317, 0.3939038813114166, 0.44504737854003906, 0.0777723640203476, 0.07291226089000702, 0.010367863811552525, 0.08759605884552002, 0.9123683571815491, 0.049569983035326004, 0.9503578543663025, 0.9999673962593079, 0.9995765089988708, 0.9991704225540161, 0.24990765750408173, 0.6030028462409973, 0.1218443512916565, 0.025258976966142654, 0.9998569488525391, 0.8696556091308594, 0.1303030401468277, 0.9994762539863586, 0.9942673444747925, 0.6594566106796265, 0.34052401781082153, 0.27384039759635925, 0.49512988328933716, 0.13174472749233246, 0.09928321838378906, 0.4745033085346222, 0.1728527843952179, 0.22767972946166992, 0.12496525049209595, 0.9981722831726074, 0.9998384714126587, 0.27615320682525635, 0.7237722873687744, 0.9999671578407288, 0.9998584389686584, 0.9993289709091187, 0.6047205328941345, 0.2503977119922638, 0.07310596108436584, 0.07173766940832138, 0.999679446220398, 0.05219493806362152, 0.9476350545883179, 0.9973859786987305, 0.9990363717079163, 0.09769115597009659, 0.9021376371383667, 0.9970061779022217, 0.17874132096767426, 0.45004117488861084, 0.371223509311676, 0.9994091391563416, 0.7099372148513794, 0.28998231887817383, 0.9956600666046143, 0.9942392110824585, 0.5743470191955566, 0.2313447743654251, 0.19428837299346924, 0.03490946814417839, 0.9650778770446777, 0.9997729659080505, 0.9989255666732788, 0.8038270473480225, 0.13754142820835114, 0.05858245864510536, 0.18156643211841583, 0.14607718586921692, 0.23086057603359222, 0.4414810240268707, 0.999226987361908, 0.9995642900466919, 0.616158664226532, 0.3838016390800476, 0.059812985360622406, 0.14597003161907196, 0.5251448750495911, 0.00041911000153049827, 0.26858964562416077], \"Term\": [\"absolutely\", \"absolutely\", \"accommodate\", \"accommodate\", \"accommodate\", \"accomodating\", \"added_bonu\", \"adorable\", \"adorable\", \"advice\", \"airbnb\", \"airbnb\", \"also\", \"also\", \"also\", \"also\", \"also\", \"amazing\", \"amazing\", \"amazingly\", \"apartment\", \"apartment\", \"apartment\", \"apartment\", \"apartment\", \"appliance\", \"area\", \"area\", \"area\", \"area\", \"area\", \"arrival\", \"arrive\", \"arrive\", \"art\", \"attraction\", \"authentic\", \"away\", \"away\", \"awesome\", \"awesome\", \"back\", \"back\", \"bad\", \"bag\", \"bar\", \"bath\", \"bathroom\", \"bathroom\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautifully\", \"bed\", \"bed\", \"bed\", \"bedroom\", \"bedroom\", \"big\", \"big\", \"big\", \"big\", \"bit\", \"bit\", \"block\", \"bottle\", \"brand\", \"breeze\", \"bus\", \"cafe\", \"cake\", \"cancel\", \"central\", \"central\", \"central\", \"centrally\", \"chair\", \"chance\", \"check\", \"check\", \"checkin\", \"china_town\", \"chinatown\", \"city\", \"city\", \"city\", \"city\", \"clean\", \"clean\", \"clean\", \"clean\", \"clean\", \"close\", \"close\", \"closet\", \"cold\", \"come\", \"come\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"common\", \"communicate\", \"communicate\", \"communicating\", \"communication\", \"communication\", \"communicative\", \"communicative\", \"communicator\", \"conveniently\", \"cook\", \"cook\", \"cook\", \"cooking\", \"corner\", \"corner\", \"day\", \"day\", \"day\", \"def\", \"definitely\", \"definitely\", \"deli\", \"describe\", \"describe\", \"describe\", \"describe\", \"describe\", \"desk\", \"dirty\", \"distance\", \"door\", \"door\", \"downtown\", \"due\", \"dust\", \"early\", \"ease\", \"easy\", \"easy\", \"easy\", \"easy\", \"elevator\", \"emily\", \"enjoy\", \"enjoy\", \"enjoy\", \"enjoy\", \"enough\", \"enough\", \"enough\", \"enough\", \"equip\", \"equip\", \"even\", \"even\", \"even\", \"ever\", \"exactly\", \"exactly\", \"exactly\", \"exceed\", \"excellent\", \"excellent\", \"excellent\", \"experience\", \"experience\", \"experience\", \"experience\", \"favorite\", \"feel\", \"feel\", \"feel\", \"ferry\", \"find\", \"find\", \"find\", \"find\", \"find\", \"fix\", \"flexible\", \"flexible\", \"flight\", \"floor\", \"floor\", \"food\", \"food\", \"food\", \"forward\", \"friendly\", \"friendly\", \"friendly\", \"friendly\", \"full\", \"full\", \"full\", \"full\", \"fully\", \"gem\", \"get\", \"get\", \"get\", \"get\", \"give\", \"give\", \"give\", \"go\", \"go\", \"go\", \"good\", \"good\", \"good\", \"good\", \"good\", \"great\", \"great\", \"great\", \"grocery\", \"hard\", \"hear\", \"heat\", \"heater\", \"help\", \"help\", \"help\", \"help\", \"helpful\", \"helpful\", \"helpful\", \"helpful\", \"highly\", \"highly\", \"highly\", \"home\", \"homey\", \"hope\", \"host\", \"host\", \"host\", \"hot\", \"hot\", \"hour\", \"hour\", \"however\", \"hustle\", \"inquiry\", \"inquiry\", \"invite\", \"issue\", \"jasmine\", \"key\", \"kitchen\", \"landlord\", \"large\", \"late\", \"late\", \"later\", \"le\", \"leave\", \"leave\", \"line\", \"linen\", \"linen\", \"little\", \"little\", \"little\", \"little\", \"little\", \"live\", \"live\", \"live\", \"living\", \"locate\", \"locate\", \"location\", \"location\", \"location\", \"location\", \"lock\", \"lot\", \"lot\", \"lot\", \"lot\", \"loud\", \"love\", \"love\", \"lucky\", \"luggage\", \"maggie\", \"make\", \"make\", \"manhatten\", \"many\", \"many\", \"many\", \"many\", \"market\", \"metro\", \"midtown\", \"min\", \"min\", \"minute\", \"minute\", \"much\", \"much\", \"much\", \"much\", \"much\", \"nearby\", \"necessary\", \"necessity\", \"need\", \"need\", \"need\", \"need\", \"need\", \"neighborhood\", \"neighborhood\", \"neighborhood\", \"neighborhood\", \"newyork\", \"nice\", \"nice\", \"nice\", \"night\", \"night\", \"night\", \"night\", \"night\", \"noise\", \"noisy\", \"park\", \"parking\", \"pauline\", \"pauline\", \"pay\", \"people\", \"people\", \"people\", \"people\", \"people\", \"perfect\", \"perfect\", \"perfect\", \"place\", \"place\", \"place\", \"place\", \"polite\", \"price\", \"price\", \"price\", \"privacy\", \"private\", \"problem\", \"problem\", \"problem\", \"process\", \"prompt\", \"prompt\", \"property\", \"public\", \"public_transport\", \"quality\", \"question\", \"question\", \"question\", \"question\", \"quick\", \"quick\", \"quick\", \"quiet\", \"quiet\", \"quiet\", \"quiet\", \"quite\", \"quite\", \"quite\", \"readily\", \"really\", \"really\", \"really\", \"really\", \"really\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"relax\", \"relax\", \"reservation\", \"respond\", \"respond\", \"response\", \"response\", \"responsive\", \"responsive\", \"responsive\", \"responsiveness\", \"restaurant\", \"ride\", \"right\", \"right\", \"right\", \"roof\", \"room\", \"roomy\", \"satisfied\", \"say\", \"say\", \"seamless\", \"separate\", \"share\", \"shop\", \"shopping\", \"size\", \"size\", \"size\", \"size\", \"sleep\", \"sleep\", \"small\", \"small\", \"small\", \"smell\", \"smooth\", \"smooth\", \"sofa\", \"soft\", \"solo\", \"soon\", \"soon\", \"space\", \"space\", \"space\", \"sparkle\", \"square\", \"stacy\", \"stair\", \"station\", \"stay\", \"stay\", \"stay\", \"stay\", \"stay\", \"stop\", \"stop\", \"store\", \"store\", \"subway\", \"suggestion\", \"suitable\", \"super\", \"super\", \"super\", \"super\", \"supermarket\", \"sure\", \"sure\", \"table\", \"tasteful\", \"thank\", \"thank\", \"thing\", \"thing\", \"thing\", \"thing\", \"time\", \"time\", \"time\", \"time\", \"timely\", \"tip\", \"towel\", \"towel\", \"train\", \"transportation\", \"treat\", \"trip\", \"trip\", \"trip\", \"trip\", \"truly\", \"tv\", \"tv\", \"ue\", \"unique\", \"unit\", \"unit\", \"unwind\", \"use\", \"use\", \"use\", \"utensil\", \"value\", \"value\", \"venue\", \"victor\", \"visit\", \"visit\", \"visit\", \"walk\", \"walk\", \"wall\", \"water_pressure\", \"welcome\", \"welcome\", \"welcome\", \"well\", \"well\", \"well\", \"well\", \"williamsburg\", \"wine\", \"wonderful\", \"wonderful\", \"work\", \"work\", \"work\", \"work\", \"work\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 5, 2, 1, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el193481165622147285215302427\", ldavis_el193481165622147285215302427_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el193481165622147285215302427\", ldavis_el193481165622147285215302427_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el193481165622147285215302427\", ldavis_el193481165622147285215302427_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook(sort=True)\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, idtoword)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fSsk4bWA3Obg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -6.575325572154794\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:504: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:506: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/ikhyvicky/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.5694115997238247\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=idtoword, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346959, 5)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6866</td>\n",
       "      <td>great, place, stay, location, host, clean, rec...</td>\n",
       "      <td>Stephanie was a wonderful host! Her apartment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4246</td>\n",
       "      <td>stay, place, make, feel, home, time, thank, ba...</td>\n",
       "      <td>Such a wonderful place and very close to the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4472</td>\n",
       "      <td>stay, place, make, feel, home, time, thank, ba...</td>\n",
       "      <td>I just got back from a trip to NYC during whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5302</td>\n",
       "      <td>stay, place, make, feel, home, time, thank, ba...</td>\n",
       "      <td>Stephanie's offered all the most important thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>great, place, stay, location, host, clean, rec...</td>\n",
       "      <td>Stephanie was really nice, ftiendly and helpfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6852</td>\n",
       "      <td>stay, place, make, feel, home, time, thank, ba...</td>\n",
       "      <td>I was pleasantly surprised with my whole stay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5188</td>\n",
       "      <td>close, walk, subway, apartment, restaurant, gr...</td>\n",
       "      <td>Stephanie's apt was great. Very convenient to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3343</td>\n",
       "      <td>stay, place, make, feel, home, time, thank, ba...</td>\n",
       "      <td>my husband and i had such a great time staying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4982</td>\n",
       "      <td>stay, place, make, feel, home, time, thank, ba...</td>\n",
       "      <td>When I first arrived at Stephanie's, she was v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5963</td>\n",
       "      <td>stay, place, make, feel, home, time, thank, ba...</td>\n",
       "      <td>awesome couldn't have been better.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             4.0              0.6866   \n",
       "1            1             2.0              0.4246   \n",
       "2            2             2.0              0.4472   \n",
       "3            3             2.0              0.5302   \n",
       "4            4             4.0              0.4902   \n",
       "5            5             2.0              0.6852   \n",
       "6            6             0.0              0.5188   \n",
       "7            7             2.0              0.3343   \n",
       "8            8             2.0              0.4982   \n",
       "9            9             2.0              0.5963   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  great, place, stay, location, host, clean, rec...   \n",
       "1  stay, place, make, feel, home, time, thank, ba...   \n",
       "2  stay, place, make, feel, home, time, thank, ba...   \n",
       "3  stay, place, make, feel, home, time, thank, ba...   \n",
       "4  great, place, stay, location, host, clean, rec...   \n",
       "5  stay, place, make, feel, home, time, thank, ba...   \n",
       "6  close, walk, subway, apartment, restaurant, gr...   \n",
       "7  stay, place, make, feel, home, time, thank, ba...   \n",
       "8  stay, place, make, feel, home, time, thank, ba...   \n",
       "9  stay, place, make, feel, home, time, thank, ba...   \n",
       "\n",
       "                                                Text  \n",
       "0  Stephanie was a wonderful host! Her apartment ...  \n",
       "1  Such a wonderful place and very close to the m...  \n",
       "2  I just got back from a trip to NYC during whic...  \n",
       "3  Stephanie's offered all the most important thi...  \n",
       "4  Stephanie was really nice, ftiendly and helpfu...  \n",
       "5  I was pleasantly surprised with my whole stay ...  \n",
       "6  Stephanie's apt was great. Very convenient to ...  \n",
       "7  my husband and i had such a great time staying...  \n",
       "8  When I first arrived at Stephanie's, she was v...  \n",
       "9                 awesome couldn't have been better.  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "example=df_dominant_topic.loc[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 5)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stephanie was a wonderful host! Her apartment was beautiful and extremely clean. We had a very nice (and affordable!) stay in the city with private room and own bathroom.\n",
      "0.9357\n",
      "\n",
      "\n",
      "Such a wonderful place and very close to the metro station on the line 1 2 3. Your She was awesome with us, It was a pleasure to stay in her appt. she's french, so last word ...\n",
      "Stephanie thank you again for your hospitality. We had a great time with you. Very available for us with lots of advice, I would particularly recommend this address which is more for a reasonable price. The subway is just 1 block from the apartment and the 1-2-3 line is the central and most convenient NYC. her neighborhood is really very nice and more !!! Go there with closed eyes.\n",
      "0.9727\n",
      "\n",
      "\n",
      "I just got back from a trip to NYC during which I stayed at Stephanie's appartment. The bedroom and private bathroom that comes with it were both kept very clean and are spacious so that I could unpack my stuff and put my clothes away in the closet. I didn't have to live out of my rucksack for ten days which made me already feel comfortable.\n",
      "The appartment is situated right at the north end of Central Park in Harlem and very close to different subway stations. I could either start my day with a morning stroll through the park and into the Upper West or Upper East Side, or catch the subway to get to Midtown, South Manhattan or Brooklyn in no time. So from a geographical vantage point the appartment is perfectly situated to discover the city.\n",
      "But apart from all these facts it was above all Stephanie with her warm and welcoming nature that really made me feel comfortable during these days. It is very nice to come \"home\" in the evening, tired after a long day's strolling around, and end the day with a little chit-chat about one's experiences before falling into bed and, with thumb-in-mouth, sleep blissfully through till the next morning.\n",
      "NYC, I will be back, and I know where I'll be staying! Thank you, Stephanie!!!\n",
      "0.962\n",
      "\n",
      "\n",
      "Stephanie's offered all the most important things: a warm welcome into a comfortable home; a comfortable bed in a quiet room; fresh & clean towels & blankets; and easy access to Manhattan.  Finding myself travelling to NYC in the future I feel I already have a open invitation to make home away from home through Stephanie's generousity.\n",
      "0.9626\n",
      "\n",
      "\n",
      "Stephanie was really nice, ftiendly and helpful. The room was perfect and it was very easy to go around the town from there. :-)\n",
      "0.9335\n",
      "\n",
      "\n",
      "I was pleasantly surprised with my whole stay at Stepahnie's place. She is the most warm hearted and interesting person and her family is the same.\n",
      "The whole place is clean aand as described in the ad. I'd go there again any time and thank Stph again for the wonderful stay.\n",
      "Thanx\n",
      "0.9501\n",
      "\n",
      "\n",
      "Stephanie's apt was great. Very convenient to anywhere in NYC you would want to go. Subway stop a block away. I would highly recommend staying there if you get a chance.\n",
      "0.624\n",
      "\n",
      "\n",
      "my husband and i had such a great time staying with stephanie! we stayed at chez chic for 3 nights and felt right at home the minute we walked in.  the room is a perfect size, plenty of room for the two of us and a good sized closet for our suitcases, everything was immaculate, clean towels and linens, and the location is great.   not only is stephanie a great hostess, she is also a great resource for things to do in the city which made our stay even better.  i would recommend stephanie to anyone traveling to new york and we cant wait to get back to nyc to see her bed and breakfast!\n",
      "0.987\n",
      "\n",
      "\n",
      "When I first arrived at Stephanie's, she was very welcoming! I had no problem finding my way from the subway at Central Park North and I never felt unsafe walking from the subway to the apartment (a 5 min walk)When I got to the apartment complex at 7th ave (Chez Chic)there was no elevator but there was a really friendly neighbor that helped me carry my luggage up the stairs. I met Stephanie's very nice husband and her two beautiful children and they were never a bother! And she even let me use her laptop so I can check my email and keep in touch with my family.\n",
      "I was free to come and go anytime I wanted to and having my own bathroom was a bonus! The bed was REALLY comfy, the air conditioning was a relief and the closet was spacious.\n",
      " Not too far up the street there was a 24 hour market that was awesome with a lot of great stuff to choose from so I was always able to make my own breakfast, lunch and dinner!! Going to and from uptown to midtown Manhattan was very easy and convenient with the subways running 24 hours (only a 25 min ride to Time Square) and there was always people around so you never felt alone!!\n",
      "Over all I really enjoyed my stay at Chez Chic and New York was a great city! I recommend any place Stephanie has available!! \n",
      "Enjoy your time in New York!\n",
      "0.9973\n",
      "\n",
      "\n",
      "awesome couldn't have been better.\n",
      "0.4007\n",
      "\n",
      "\n",
      "It was a great week at \"chez chic\". Stephanie and her family were really friendly and she gave us some advices to visit the town. The room was comfortable and the flat was really well situated (5 minutes from subway). We would recommend this place to anyone!\n",
      "0.944\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in example.Text:\n",
    "    # Assess sentiment.\n",
    "    sentiment = sia.polarity_scores(sentence)[\"compound\"]\n",
    "    print(sentence)\n",
    "    print(sentiment)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores=[]\n",
    "for sentence in df_dominant_topic.Text:\n",
    "    sentiment = sia.polarity_scores(sentence)[\"compound\"]\n",
    "    sentiment_scores.append(sentiment)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic['sentiment_score'] = pd.Series(sentiment_scores, index=df_dominant_topic.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346959, 6)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6866</td>\n",
       "      <td>great, place, stay, location, host, clean, rec...</td>\n",
       "      <td>Stephanie was a wonderful host! Her apartment ...</td>\n",
       "      <td>0.9357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4246</td>\n",
       "      <td>stay, place, make, feel, home, time, thank, ba...</td>\n",
       "      <td>Such a wonderful place and very close to the m...</td>\n",
       "      <td>0.9727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4472</td>\n",
       "      <td>stay, place, make, feel, home, time, thank, ba...</td>\n",
       "      <td>I just got back from a trip to NYC during whic...</td>\n",
       "      <td>0.9620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5302</td>\n",
       "      <td>stay, place, make, feel, home, time, thank, ba...</td>\n",
       "      <td>Stephanie's offered all the most important thi...</td>\n",
       "      <td>0.9626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>great, place, stay, location, host, clean, rec...</td>\n",
       "      <td>Stephanie was really nice, ftiendly and helpfu...</td>\n",
       "      <td>0.9335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             4.0              0.6866   \n",
       "1            1             2.0              0.4246   \n",
       "2            2             2.0              0.4472   \n",
       "3            3             2.0              0.5302   \n",
       "4            4             4.0              0.4902   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  great, place, stay, location, host, clean, rec...   \n",
       "1  stay, place, make, feel, home, time, thank, ba...   \n",
       "2  stay, place, make, feel, home, time, thank, ba...   \n",
       "3  stay, place, make, feel, home, time, thank, ba...   \n",
       "4  great, place, stay, location, host, clean, rec...   \n",
       "\n",
       "                                                Text  sentiment_score  \n",
       "0  Stephanie was a wonderful host! Her apartment ...           0.9357  \n",
       "1  Such a wonderful place and very close to the m...           0.9727  \n",
       "2  I just got back from a trip to NYC during whic...           0.9620  \n",
       "3  Stephanie's offered all the most important thi...           0.9626  \n",
       "4  Stephanie was really nice, ftiendly and helpfu...           0.9335  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get a sense of what negative comments will look like\n",
    "negative_sentiments=df_dominant_topic[df_dominant_topic['sentiment_score']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sentiments.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8996, 6)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_sentiments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3565</th>\n",
       "      <td>162817</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7557</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>This is a filthy hole in a filthy old building...</td>\n",
       "      <td>-0.9971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>111046</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7482</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>Dangerous host \\nI really hate it when I write...</td>\n",
       "      <td>-0.9966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8788</th>\n",
       "      <td>338855</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7021</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>We had a very bad experience with this Airbnb ...</td>\n",
       "      <td>-0.9965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>169226</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8036</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>Here is a list of issues to consider. We reach...</td>\n",
       "      <td>-0.9963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7510</th>\n",
       "      <td>297779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7635</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>I really do not enjoy having to write bad revi...</td>\n",
       "      <td>-0.9963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6872</th>\n",
       "      <td>277427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8042</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>From the moment me and my sister booked this A...</td>\n",
       "      <td>-0.9956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>82528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7815</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>BAD BAD TERRIEBLE. FROM THE BEGINNING. Very ru...</td>\n",
       "      <td>-0.9949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>12044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7388</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>During the stay, Zooey and I felt very happy t...</td>\n",
       "      <td>-0.9948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>57391</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7901</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>My wife and 4 kids had a very dissatisfying st...</td>\n",
       "      <td>-0.9947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>124547</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>We have used AirBnb and (Hidden by Airbnb) as ...</td>\n",
       "      <td>-0.9946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8839</th>\n",
       "      <td>340938</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4998</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>I booked this home on Airbnb in Manhattan from...</td>\n",
       "      <td>-0.9942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6859</th>\n",
       "      <td>276938</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6237</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>3 of the 4  nights in the apartment, the entir...</td>\n",
       "      <td>-0.9939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4555</th>\n",
       "      <td>202339</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8810</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>TERRIBLE EXPERIENCE: ILLEGAL LISTING AND UNRES...</td>\n",
       "      <td>-0.9937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>19065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6426</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>I was going to stay in this place for 4 days. ...</td>\n",
       "      <td>-0.9935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>113556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7169</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>HORRIBLE, HORRIBLE, HORRIBLE NOISY, NOISY, NOI...</td>\n",
       "      <td>-0.9928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>244415</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7811</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>The main reason for booking this property was ...</td>\n",
       "      <td>-0.9921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>248670</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7480</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>I considered this stay as a \"3D Guantanamo Bay...</td>\n",
       "      <td>-0.9920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>134979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5030</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>I know I write this evaluation landlord might ...</td>\n",
       "      <td>-0.9920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>215831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7504</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>First of all, the basement basically stinks. I...</td>\n",
       "      <td>-0.9917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8853</th>\n",
       "      <td>341754</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>host, day, night, arrival, check, apartment, g...</td>\n",
       "      <td>This was by far the worst absolute AirBNB stay...</td>\n",
       "      <td>-0.9916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "3565       162817             1.0              0.7557   \n",
       "2277       111046             1.0              0.7482   \n",
       "8788       338855             1.0              0.7021   \n",
       "3748       169226             1.0              0.8036   \n",
       "7510       297779             1.0              0.7635   \n",
       "6872       277427             1.0              0.8042   \n",
       "1572        82528             1.0              0.7815   \n",
       "212         12044             1.0              0.7388   \n",
       "1024        57391             1.0              0.7901   \n",
       "2526       124547             1.0              0.6990   \n",
       "8839       340938             1.0              0.4998   \n",
       "6859       276938             1.0              0.6237   \n",
       "4555       202339             1.0              0.8810   \n",
       "301         19065             1.0              0.6426   \n",
       "2338       113556             1.0              0.7169   \n",
       "5939       244415             1.0              0.7811   \n",
       "6064       248670             1.0              0.7480   \n",
       "2835       134979             1.0              0.5030   \n",
       "4958       215831             1.0              0.7504   \n",
       "8853       341754             1.0              0.8448   \n",
       "\n",
       "                                               Keywords  \\\n",
       "3565  host, day, night, arrival, check, apartment, g...   \n",
       "2277  host, day, night, arrival, check, apartment, g...   \n",
       "8788  host, day, night, arrival, check, apartment, g...   \n",
       "3748  host, day, night, arrival, check, apartment, g...   \n",
       "7510  host, day, night, arrival, check, apartment, g...   \n",
       "6872  host, day, night, arrival, check, apartment, g...   \n",
       "1572  host, day, night, arrival, check, apartment, g...   \n",
       "212   host, day, night, arrival, check, apartment, g...   \n",
       "1024  host, day, night, arrival, check, apartment, g...   \n",
       "2526  host, day, night, arrival, check, apartment, g...   \n",
       "8839  host, day, night, arrival, check, apartment, g...   \n",
       "6859  host, day, night, arrival, check, apartment, g...   \n",
       "4555  host, day, night, arrival, check, apartment, g...   \n",
       "301   host, day, night, arrival, check, apartment, g...   \n",
       "2338  host, day, night, arrival, check, apartment, g...   \n",
       "5939  host, day, night, arrival, check, apartment, g...   \n",
       "6064  host, day, night, arrival, check, apartment, g...   \n",
       "2835  host, day, night, arrival, check, apartment, g...   \n",
       "4958  host, day, night, arrival, check, apartment, g...   \n",
       "8853  host, day, night, arrival, check, apartment, g...   \n",
       "\n",
       "                                                   Text  sentiment_score  \n",
       "3565  This is a filthy hole in a filthy old building...          -0.9971  \n",
       "2277  Dangerous host \\nI really hate it when I write...          -0.9966  \n",
       "8788  We had a very bad experience with this Airbnb ...          -0.9965  \n",
       "3748  Here is a list of issues to consider. We reach...          -0.9963  \n",
       "7510  I really do not enjoy having to write bad revi...          -0.9963  \n",
       "6872  From the moment me and my sister booked this A...          -0.9956  \n",
       "1572  BAD BAD TERRIEBLE. FROM THE BEGINNING. Very ru...          -0.9949  \n",
       "212   During the stay, Zooey and I felt very happy t...          -0.9948  \n",
       "1024  My wife and 4 kids had a very dissatisfying st...          -0.9947  \n",
       "2526  We have used AirBnb and (Hidden by Airbnb) as ...          -0.9946  \n",
       "8839  I booked this home on Airbnb in Manhattan from...          -0.9942  \n",
       "6859  3 of the 4  nights in the apartment, the entir...          -0.9939  \n",
       "4555  TERRIBLE EXPERIENCE: ILLEGAL LISTING AND UNRES...          -0.9937  \n",
       "301   I was going to stay in this place for 4 days. ...          -0.9935  \n",
       "2338  HORRIBLE, HORRIBLE, HORRIBLE NOISY, NOISY, NOI...          -0.9928  \n",
       "5939  The main reason for booking this property was ...          -0.9921  \n",
       "6064  I considered this stay as a \"3D Guantanamo Bay...          -0.9920  \n",
       "2835  I know I write this evaluation landlord might ...          -0.9920  \n",
       "4958  First of all, the basement basically stinks. I...          -0.9917  \n",
       "8853  This was by far the worst absolute AirBNB stay...          -0.9916  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_sentiments.sort_values('sentiment_score').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We had a very bad experience with this Airbnb stay. Zheng was very friendly as a person and tried to help, but there were so many things wrong and illegal about her setup, that it led to the worst Airbnb experience we have ever had. Zheng has put her rental apartment on Airbnb without permission from her leasing office (as she told us herself). Hence, she lied about many things in her listing and to us when we booked. She gave us a wrong  address since she didn't want us to reach her main entrance/lobby or use the main elevator since she thought her leasing agency folks will catch her doing Airbnb illegally.  Further, she asked us not to use the lobby, main elevator and the correct address (anybody for deliveries would then reach the lobby and meet the leasing office people). Instead, she asked us to use a freight elevator on one side of the building to enter the property. This led to a series of bad experiences for us. I travel for business and I book using Airbnb for business. One of the main reasons I do Airbnb for business is so that I can cook my meals. Otherwise, I would stay at any 5 star hotel near my office. Because Zheng asked us not to use the main entrance and address, we couldn't get grocery delivered from Amazon Prime, we had to wait 50 min - 1 hr in bitter cold in the evenings to get our food delivered from Grubhub and Ubereats because we had to wait on the road outside an address a block away because Zheng thought it was safe rather than using the address of her apartment. And equally disappointingly,  Zheng had misleading and fake photos of her kitchen in her listing. The kitchen and bathroom photos in her listing are not the photos of her Airbnb listing. Her kitchen photo misled us into believing we could use her kitchen. Zheng didn't have kitchen utensils to cook food, or even serve/eat food, water etc. No water glasses, no kettles for tea/water heating, no plates, spoons, forks, no kitchen rolls, no spatulas, we couldn't cook anything in her house. And we really struggled to get food delivered because of her instructions not to use the right address or the property lobby.  Likewise, here photo of her bathroom is also not her apartment photo. It's taken from her leasing office's photo. Her bodywash, showergel bottles were empty, shampoo was also almost over. The floor of her apartment was sticky, needed cleaning. Basically, she didn't have any amenities which I'm used to having when I book with Airbnb for business. I've always had great experiences with Airbnb for business before this, and this is the first time I'm seeing a host list their apartment illegally, use misleading and fake photos, wrong information, address and thereby cause so many problems. \\nShe had given us one access card for her apartment and told us if we lose it, it'll cost her $50 and 7 days to get it. This information is not written anywhere in her listing, just like none of her lies are written anywhere in her listing such as you can't use her address, she'll give you a different address etc. In all the chaos of going away one block, using some side elevator and side entrance, and not being able to use the main entrance to the building, and waiting for long times to get food deliveries, we eventually misplaced the one access key given to us. Zheng sent us an additional bill of $70 for that using resolution center. Yet, this is not written anywhere in her listing, just like her incorrect address. \\n\\nI'm a long time Airbnb user, and I used to host on Airbnb as well, with all 5 star reviews. It's very important that Airbnb maintains its quality and ethical practices and oust such hosts who're illegally hosting on Airbnb. Otherwise, business travelers using Airbnb for business will have rough experiences and huge experience mismatches.\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_sentiments.Text.iloc[8788]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_sentiments.Dominant_Topic.nunique() #this just means people  can talk negative things for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting them back together\n",
    "df=pd.read_csv('./removed_january.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346959, 6)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2515</td>\n",
       "      <td>198</td>\n",
       "      <td>2008-10-13</td>\n",
       "      <td>2603</td>\n",
       "      <td>Jenny</td>\n",
       "      <td>Stephanie was a wonderful host! Her apartment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2515</td>\n",
       "      <td>859</td>\n",
       "      <td>2009-03-08</td>\n",
       "      <td>8455</td>\n",
       "      <td>Roland</td>\n",
       "      <td>Such a wonderful place and very close to the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2515</td>\n",
       "      <td>1083</td>\n",
       "      <td>2009-03-25</td>\n",
       "      <td>9759</td>\n",
       "      <td>Cem</td>\n",
       "      <td>I just got back from a trip to NYC during whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2515</td>\n",
       "      <td>1107</td>\n",
       "      <td>2009-03-27</td>\n",
       "      <td>9193</td>\n",
       "      <td>Holly</td>\n",
       "      <td>Stephanie's offered all the most important thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2515</td>\n",
       "      <td>2175</td>\n",
       "      <td>2009-05-09</td>\n",
       "      <td>7048</td>\n",
       "      <td>Alessandra</td>\n",
       "      <td>Stephanie was really nice, ftiendly and helpfu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id    id        date  reviewer_id reviewer_name  \\\n",
       "0        2515   198  2008-10-13         2603         Jenny   \n",
       "1        2515   859  2009-03-08         8455        Roland   \n",
       "2        2515  1083  2009-03-25         9759           Cem   \n",
       "3        2515  1107  2009-03-27         9193         Holly   \n",
       "4        2515  2175  2009-05-09         7048    Alessandra   \n",
       "\n",
       "                                            comments  \n",
       "0  Stephanie was a wonderful host! Her apartment ...  \n",
       "1  Such a wonderful place and very close to the m...  \n",
       "2  I just got back from a trip to NYC during whic...  \n",
       "3  Stephanie's offered all the most important thi...  \n",
       "4  Stephanie was really nice, ftiendly and helpfu...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346959, 6)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6866</td>\n",
       "      <td>great, place, stay, location, host, clean, rec...</td>\n",
       "      <td>Stephanie was a wonderful host! Her apartment ...</td>\n",
       "      <td>0.9357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4246</td>\n",
       "      <td>stay, place, make, feel, home, time, thank, ba...</td>\n",
       "      <td>Such a wonderful place and very close to the m...</td>\n",
       "      <td>0.9727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4472</td>\n",
       "      <td>stay, place, make, feel, home, time, thank, ba...</td>\n",
       "      <td>I just got back from a trip to NYC during whic...</td>\n",
       "      <td>0.9620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5302</td>\n",
       "      <td>stay, place, make, feel, home, time, thank, ba...</td>\n",
       "      <td>Stephanie's offered all the most important thi...</td>\n",
       "      <td>0.9626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>great, place, stay, location, host, clean, rec...</td>\n",
       "      <td>Stephanie was really nice, ftiendly and helpfu...</td>\n",
       "      <td>0.9335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             4.0              0.6866   \n",
       "1            1             2.0              0.4246   \n",
       "2            2             2.0              0.4472   \n",
       "3            3             2.0              0.5302   \n",
       "4            4             4.0              0.4902   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  great, place, stay, location, host, clean, rec...   \n",
       "1  stay, place, make, feel, home, time, thank, ba...   \n",
       "2  stay, place, make, feel, home, time, thank, ba...   \n",
       "3  stay, place, make, feel, home, time, thank, ba...   \n",
       "4  great, place, stay, location, host, clean, rec...   \n",
       "\n",
       "                                                Text  sentiment_score  \n",
       "0  Stephanie was a wonderful host! Her apartment ...           0.9357  \n",
       "1  Such a wonderful place and very close to the m...           0.9727  \n",
       "2  I just got back from a trip to NYC during whic...           0.9620  \n",
       "3  Stephanie's offered all the most important thi...           0.9626  \n",
       "4  Stephanie was really nice, ftiendly and helpfu...           0.9335  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop original non-translated comments\n",
    "df.drop(columns=['comments'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic.drop(columns=['Document_No'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the two together \n",
    "frames=[df,df_dominant_topic]\n",
    "finaldf=pd.concat(frames,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2515</td>\n",
       "      <td>198</td>\n",
       "      <td>2008-10-13</td>\n",
       "      <td>2603</td>\n",
       "      <td>Jenny</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6866</td>\n",
       "      <td>great, place, stay, location, host, clean, rec...</td>\n",
       "      <td>Stephanie was a wonderful host! Her apartment ...</td>\n",
       "      <td>0.9357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2515</td>\n",
       "      <td>859</td>\n",
       "      <td>2009-03-08</td>\n",
       "      <td>8455</td>\n",
       "      <td>Roland</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4246</td>\n",
       "      <td>stay, place, make, feel, home, time, thank, ba...</td>\n",
       "      <td>Such a wonderful place and very close to the m...</td>\n",
       "      <td>0.9727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2515</td>\n",
       "      <td>1083</td>\n",
       "      <td>2009-03-25</td>\n",
       "      <td>9759</td>\n",
       "      <td>Cem</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4472</td>\n",
       "      <td>stay, place, make, feel, home, time, thank, ba...</td>\n",
       "      <td>I just got back from a trip to NYC during whic...</td>\n",
       "      <td>0.9620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2515</td>\n",
       "      <td>1107</td>\n",
       "      <td>2009-03-27</td>\n",
       "      <td>9193</td>\n",
       "      <td>Holly</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5302</td>\n",
       "      <td>stay, place, make, feel, home, time, thank, ba...</td>\n",
       "      <td>Stephanie's offered all the most important thi...</td>\n",
       "      <td>0.9626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2515</td>\n",
       "      <td>2175</td>\n",
       "      <td>2009-05-09</td>\n",
       "      <td>7048</td>\n",
       "      <td>Alessandra</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>great, place, stay, location, host, clean, rec...</td>\n",
       "      <td>Stephanie was really nice, ftiendly and helpfu...</td>\n",
       "      <td>0.9335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  listing_id    id        date  reviewer_id reviewer_name  \\\n",
       "0      0        2515   198  2008-10-13         2603         Jenny   \n",
       "1      1        2515   859  2009-03-08         8455        Roland   \n",
       "2      2        2515  1083  2009-03-25         9759           Cem   \n",
       "3      3        2515  1107  2009-03-27         9193         Holly   \n",
       "4      4        2515  2175  2009-05-09         7048    Alessandra   \n",
       "\n",
       "   Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0             4.0              0.6866   \n",
       "1             2.0              0.4246   \n",
       "2             2.0              0.4472   \n",
       "3             2.0              0.5302   \n",
       "4             4.0              0.4902   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  great, place, stay, location, host, clean, rec...   \n",
       "1  stay, place, make, feel, home, time, thank, ba...   \n",
       "2  stay, place, make, feel, home, time, thank, ba...   \n",
       "3  stay, place, make, feel, home, time, thank, ba...   \n",
       "4  great, place, stay, location, host, clean, rec...   \n",
       "\n",
       "                                                Text  sentiment_score  \n",
       "0  Stephanie was a wonderful host! Her apartment ...           0.9357  \n",
       "1  Such a wonderful place and very close to the m...           0.9727  \n",
       "2  I just got back from a trip to NYC during whic...           0.9620  \n",
       "3  Stephanie's offered all the most important thi...           0.9626  \n",
       "4  Stephanie was really nice, ftiendly and helpfu...           0.9335  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346959, 11)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.to_csv('./finaldf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now the tedious part is to link listing id to negative sentiment scores\n",
    "final_negative_sentiments=finaldf[finaldf['sentiment_score']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8996, 11)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_negative_sentiments.shape  #8996 comments with negative comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3840"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_negative_sentiments.listing_id.nunique() #3840 unique listings out of 13322 listings are negatively commented  29% of the listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13322"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.listing_id.nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27,\n",
       " 25,\n",
       " 22,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 16,\n",
       " 16,\n",
       " 15,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " ...]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(final_negative_sentiments['listing_id'].value_counts(),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_sentiments=finaldf.groupby(['listing_id','Dominant_Topic']).agg({'index':'count', 'sentiment_score':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_id</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2515</th>\n",
       "      <th>0.0</th>\n",
       "      <td>29</td>\n",
       "      <td>0.773814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>12</td>\n",
       "      <td>0.346767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>85</td>\n",
       "      <td>0.867938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>22</td>\n",
       "      <td>0.851195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>27</td>\n",
       "      <td>0.882193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2539</th>\n",
       "      <th>0.0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.584750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.943450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.699100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.624900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3330</th>\n",
       "      <th>0.0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.924525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.323033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>16</td>\n",
       "      <td>0.964581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.981600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>12</td>\n",
       "      <td>0.911567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5022</th>\n",
       "      <th>0.0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.725500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.990300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.889125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5216</th>\n",
       "      <th>0.0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.729980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.707267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.880950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           index  sentiment_score\n",
       "listing_id Dominant_Topic                        \n",
       "2515       0.0                29         0.773814\n",
       "           1.0                12         0.346767\n",
       "           2.0                85         0.867938\n",
       "           3.0                22         0.851195\n",
       "           4.0                27         0.882193\n",
       "2539       0.0                 4         0.584750\n",
       "           2.0                 2         0.943450\n",
       "           3.0                 2         0.699100\n",
       "           4.0                 1         0.624900\n",
       "3330       0.0                 4         0.924525\n",
       "           1.0                 3         0.323033\n",
       "           2.0                16         0.964581\n",
       "           3.0                 4         0.981600\n",
       "           4.0                12         0.911567\n",
       "5022       0.0                 4         0.725500\n",
       "           2.0                 1         0.990300\n",
       "           4.0                 4         0.889125\n",
       "5216       0.0                 5         0.729980\n",
       "           1.0                 9         0.707267\n",
       "           2.0                 6         0.880950"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_sentiments.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_sentiments.to_csv('./listings_sentiments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO/mrQMX3V/5GQ7tvsCM8CW",
   "machine_shape": "hm",
   "name": "Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
